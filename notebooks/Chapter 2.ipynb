{
 "metadata": {
  "name": "",
  "signature": "sha256:8a85e7b27661467a8e5a609dc4933ce5fe8e878d8ca6b79d188bfe04be075717"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "2. A Short Tour of the Predictive Modeling Process"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Introduce the broad concepts of modeling building, i.e. building candidate models and selecting the op"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2.1 Case Study: Predicting Fuel Economy"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check if data exists:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls -l ../datasets/FuelEconomy/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this study, we are only interested in data from 2010 and 2011. Use the DataFrame data type from **pandas** to store the files. It is very similar to the statistical package **R**'s data frame."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "cars10 = pd.read_csv(\"../datasets/FuelEconomy/cars2010.csv\")\n",
      "cars11 = pd.read_csv(\"../datasets/FuelEconomy/cars2011.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cars10.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check if there is any missing values 'NAN' in this dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cars10.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cars10.shape\n",
      "print cars11.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We only restrict ourselves to a single predictor 'EngDispl' and the response 'FE' in this introductory illustration."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cars10_feature = cars10.get(['EngDispl'])\n",
      "cars10_target = cars10.get(['FE'])\n",
      "cars11_feature = cars11.get(['EngDispl'])\n",
      "cars11_target = cars11.get(['FE'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cars10_feature.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cars10_target.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generally, we want to first visulize the datasets to get a better understanding before doing anything crazy. Since there is one predicator, a simple scatter plot would do the trick. The characteristics from the visulization may suggest important and necessary pre-processing steps."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Some nice default configuration for plots\n",
      "plt.rcParams['figure.figsize'] = 10, 7.5\n",
      "plt.rcParams['axes.grid'] = True\n",
      "plt.gray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, (ax1, ax2) = plt.subplots(1, 2, sharey = True)\n",
      "\n",
      "ax1.scatter(cars10_feature, cars10_target)\n",
      "ax1.set_title('2010 Model Year')\n",
      "ax2.scatter(cars11_feature, cars11_target)\n",
      "ax2.set_title('2011 Model Year')\n",
      "\n",
      "fig.text(0.5, 0.04, 'Engine Displacement', ha='center', va='center')\n",
      "fig.text(0.06, 0.5, 'Fuel Efficiency (MPG)', ha='center', va='center', rotation='vertical')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because of the nature of this problem, i.e. predict the MPG for a new car line, we take the 2010 data as *training set* and the 2011 data as *test set*. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define the evaluation metric: root mean squared error (RMSE)\n",
      "from sklearn.metrics import mean_squared_error\n",
      "\n",
      "def rmse(y_actual, y_predicted):\n",
      "    '''calculate Root Mean Squared Error'''\n",
      "    return np.sqrt(mean_squared_error(y_actual, y_predicted))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A good starting point is the simple linear model \n",
      "$$y = \\beta_0 + \\beta_1x,$$\n",
      "where $y$ is the Fuel Efficiency (MPG) and $x$ is the Engine Displacement."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# simple linear model\n",
      "from sklearn.linear_model import LinearRegression\n",
      "\n",
      "reg = LinearRegression()\n",
      "reg.fit(cars10_feature, cars10_target)\n",
      "print \"Least square estimate: intercept = {0}, coefficient ={1}\".format(reg.intercept_, reg.coef_[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.linspace(np.min(cars10_feature)[0], np.max(cars10_feature)[0])[:, np.newaxis]\n",
      "y = reg.predict(X)\n",
      "cars10_target_pred = reg.predict(cars10_feature)\n",
      "y_range = np.linspace(np.min(cars10_target)[0], np.max(cars10_target)[0])[:, np.newaxis]\n",
      "\n",
      "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
      "\n",
      "ax1.scatter(cars10_feature, cars10_target)\n",
      "ax1.plot(X, y, 'r')\n",
      "ax1.set_title('2010 Model Year')\n",
      "ax1.set_xlabel('Engine Displacement')\n",
      "ax1.set_ylabel('Fuel Efficiency (MPG)')\n",
      "\n",
      "ax2.scatter(cars10_target, cars10_target_pred)\n",
      "ax2.plot(y_range, y_range, 'r--')\n",
      "ax2.set_xlabel('Observed')\n",
      "ax2.set_ylabel('Predicted')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The left-hand panel shows the training set data with a linear model fit defined by the estimated slope and intercept. The right-hand panel plots the observed and predicted MPG. These plots demonstrate that this model misses some of the patterns in the data, such as under-predicting fuel efficiency when the displacement is less than 2L or above 6L"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# calculate root mean square error (RMSE)\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "scores = np.sqrt(np.abs(cross_val_score(reg, cars10_feature, cars10_target, cv=10, scoring='mean_squared_error')))\n",
      "print \"RMSE: {0}\".format(np.mean(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Notice** that simply re-predict the training set data is like to result in overly optimistic estimation of RMSE. An alternative approach for quantifying how well the model operates is to use *resampling* techniques, e.g. 10-fold cross-validation. We will cover that in Chapter 4."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looking at the previous figure, it is conceivable that the problem might be solved by introducing some non-linearity in the model. The most basic approach is to supplement the simple linear model with additional complexity, e.g.\n",
      "$$y = \\beta_0 + \\beta_1 x + \\beta_2 x^2,$$\n",
      "which is referred to as *quadratic model*."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# quadratic model\n",
      "from sklearn.preprocessing import PolynomialFeatures\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "quad = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
      "quad.fit(cars10_feature, cars10_target)\n",
      "\n",
      "scores = np.sqrt(np.abs(cross_val_score(quad, cars10_feature, cars10_target, cv=10, scoring='mean_squared_error')))\n",
      "print \"RMSE: {0}\".format(np.mean(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Reduce in the RMSE may suggest that this model is a better fit to the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.linspace(np.min(cars10_feature)[0], np.max(cars10_feature)[0])[:, np.newaxis]\n",
      "y = quad.predict(X)\n",
      "cars10_target_pred = quad.predict(cars10_feature)\n",
      "y_range = np.linspace(np.min(cars10_target)[0], np.max(cars10_target)[0])[:, np.newaxis]\n",
      "\n",
      "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
      "\n",
      "ax1.scatter(cars10_feature, cars10_target)\n",
      "ax1.plot(X, y, 'r')\n",
      "ax1.set_title('2010 Model Year')\n",
      "ax1.set_xlabel('Engine Displacement')\n",
      "ax1.set_ylabel('Fuel Efficiency (MPG)')\n",
      "\n",
      "ax2.scatter(cars10_target, cars10_target_pred)\n",
      "ax2.plot(y_range, y_range, 'r--')\n",
      "ax2.set_xlabel('Observed')\n",
      "ax2.set_ylabel('Predicted')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One issue with quadratic models is that they can perform poorly on the extremes of the predictor. From the above figure, one might notice that predicting new vehicles with large displacement values may produce inaccurate results."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are other approaches for creating sophisticated relationships between the predictors and outcome. One particular technique is the multivariate adaptive regression spline (MARS) model (Friedman (1991)). When used with a single predictor, MARS can fit separate linear regression lines for different ranges of engine displacement. This model, like many machine learning algorithms, has a *tuning parameter* which cannot be directly estimated from the data. While the MARS model has internal algorithms for making this dtermination, the user can try different values and use resampling to determin the appropriate value. Once the value is found, a final MARS model would be fit using all the training set data and used for prediction."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A Python module *py-earth* on Github implemented the MARS and is likely to be merged into *sklearn* in the near future (see [this](https://github.com/scikit-learn/scikit-learn/issues/845) issue)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# MARS\n",
      "from pyearth import Earth\n",
      "\n",
      "mars = Earth()\n",
      "mars.fit(cars10_feature, cars10_target)\n",
      "scores = np.sqrt(np.abs(cross_val_score(mars, cars10_feature, cars10_target, cv=10, scoring='mean_squared_error')))\n",
      "print \"RMSE: {0}\".format(np.mean(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "RMSE of MARS is similar to that of quadratic regression."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.linspace(np.min(cars10_feature)[0], np.max(cars10_feature)[0])[:, np.newaxis]\n",
      "y = mars.predict(X)\n",
      "cars10_target_pred = mars.predict(cars10_feature)\n",
      "y_range = np.linspace(np.min(cars10_target)[0], np.max(cars10_target)[0])[:, np.newaxis]\n",
      "\n",
      "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
      "\n",
      "ax1.scatter(cars10_feature, cars10_target)\n",
      "ax1.plot(X, y, 'r')\n",
      "ax1.set_title('2010 Model Year')\n",
      "ax1.set_xlabel('Engine Displacement')\n",
      "ax1.set_ylabel('Fuel Efficiency (MPG)')\n",
      "\n",
      "ax2.scatter(cars10_target, cars10_target_pred)\n",
      "ax2.plot(y_range, y_range, 'r--')\n",
      "ax2.set_xlabel('Observed')\n",
      "ax2.set_ylabel('Predicted')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Both quadratic model and MARS are evaluated on the test set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.linspace(np.min(cars11_feature)[0], np.max(cars11_feature)[0])[:, np.newaxis]\n",
      "\n",
      "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
      "\n",
      "ax1.scatter(cars11_feature, cars11_target)\n",
      "ax1.plot(X, quad.predict(X), 'r')\n",
      "ax1.set_xlabel('Engine Displacement')\n",
      "ax1.set_ylabel('Fuel Efficiency (MPG)')\n",
      "ax1.set_title('Quadratic model')\n",
      "\n",
      "ax2.scatter(cars11_feature, cars11_target)\n",
      "ax2.plot(X, mars.predict(X), 'r')\n",
      "ax2.set_xlabel('Engine Displacement')\n",
      "ax2.set_ylabel('Fuel Efficiency (MPG)')\n",
      "ax2.set_title('MARS')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# RMSE\n",
      "quad_scores = np.sqrt(np.abs(cross_val_score(quad, cars11_feature, cars11_target, cv=10, scoring='mean_squared_error')))\n",
      "mars_scores = np.sqrt(np.abs(cross_val_score(mars, cars11_feature, cars11_target, cv=10, scoring='mean_squared_error')))\n",
      "\n",
      "print \"Quadratic model RMSE: {0} and MARS RMSE: {1}\".format(np.mean(quad_scores), np.mean(mars_scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first thing to notice is that both scores are very similar, which indicates that either model is appropriate for this task. Also, both scores are lower than their previous values (fitted to 2010 data) as we would expect."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2.2 Themes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are several aspects of the model building process that are worth discussing further."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Data Splitting"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- How we allocate data to certain tasks, e.g. model building, evaluating performance?\n",
      "    - extrapolation: order matters\n",
      "    - interpolation: a simple random sample of the data\n",
      "- How much data should be allocated to the training and test sets?\n",
      "    - small data sets: resampling techniques, i.e. no test set\n",
      "    - large data sets"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Predictor Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Feature selection: the process of determining the minimum set of relevant predictors needed by the model."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Estimating Performance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Quantitative assessments of statistics (using resampling techniques)\n",
      "- Visualization"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Evaluating Several Models"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\"No Free Lunch\" Theorem - Try a wide variety of techniques then determine which model to focus on."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Model Selection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- between models\n",
      "- within the same model\n",
      "\n",
      "Rely on cross-validation and the test set to produce quantitative assessments of the models to make the choice."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2.3 Summary"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get a reliable, trustworthy model for predicting new samples, we must first understand the data and the objective of the modeling."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}